unique_id,review_count,url,title,abstract,user,vote,in_progress,time
272,0,https://doi.org/10.1145/3319535.3363264,Nickel to Lego: Using Foolgle&lt;/&gt; to Create Adversarial Examples to Fool Google Cloud Speech-to-Text API,"
		<p>Many companies offer automatic speech recognition or Speech-to-Text APIs for use in diverse applications. However, audio classification algorithms trained with deep neural networks (DNNs) can sometimes misclassify adversarial examples, posing a significant threat to critical applications. In this paper, we present a novel way to create adversarial audio examples using a genetic algorithm. Our algorithm creates adversarial examples by iteratively adding perturbations to the original audio signal. Unlike most white-box adversarial example generations, our approach does not require knowledge about the target DNN's model and parameters (black-box) and heavy computational power of GPU resources. To show the feasibility of the proposed idea, we implement a tool called, Foolgle, using a genetic algorithm that performs untargeted attacks to create adversarial audio examples and evaluate those with the state-of-the-art Google Cloud Speech-to-Text API. Our preliminary experiment results show that Foolgle deceives the API with a success probability of 86%.</p>
	------endofabstract------272",none,none,no,1691766425.825698
